{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA6202: Laboratorio de Ciencia de Datos\n",
    "\n",
    "**Profesor: Nicolás Caro**\n",
    "\n",
    "**05/06/2020 - E2 S9**\n",
    "\n",
    "\n",
    "**Integrantes del grupo**:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2\n",
    "\n",
    "La estructura de esta evaluación consta de 5 preguntas. Tenga en cuenta que un problema de programación puede (por lo general) resolverse de múltiples maneras. Sin embargo, para optar al puntaje completo en cada pregunta, siga las indicaciones de los enunciados y utilice solo herramientas vistas en el curso. \n",
    "\n",
    "En lo que sigue de la evaluación, **no** estará permitido usar librerías ni módulos diferentes a los declarados en la siguiente celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "%load_ext line_profiler\n",
    "%load_ext cython\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import pickle as pk\n",
    "import os\n",
    "import warnings\n",
    "import math\n",
    "import glob\n",
    "\n",
    "from scipy import stats\n",
    "from functools import lru_cache\n",
    "from scipy import sparse \n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from multiprocessing import Process, cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de este ejercicio es implementar **eficientemente** el algoritmo de regresión logística bayesiana, entrenado mediante un método de Markov Chain Montecarlo (MCMC), específicamente Metropolis-Hastings.\n",
    "\n",
    "Para trabajar en esta evaluación, construya un repositorio Git y resuelva las preguntas de este notebook utilizando tal repositorio. El formato de entrega es un archivo **.zip** con el repositorio correspondiente a este trabajo, no olvide incluir la carpeta `.git` asociada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminares\n",
    "\n",
    "Se trabajará en un problema de **clasificación binaria** sobre un conjunto de datos. Tal conjunto, describe  el comportamiento de clientes en un banco frente a una llamada telefónica, en la cual se les ofrece un depósito a plazo. \n",
    "\n",
    "La variable objetivo del conjunto de datos describe si el cliente se subscribió o no luego de la llamada. Si bien no es necesario entender el significado de cada variable para el correcto desarrollo del ejercicio, en `data/readme.md` encontrarán una descripción de estas.\n",
    "\n",
    "#### Carga de datos\n",
    "Compruebe que la siguiente celda coincide con este output:\n",
    "\n",
    "```\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 11162 entries, 0 to 11161\n",
    "Data columns (total 17 columns):\n",
    " #   Column        Non-Null Count  Dtype   \n",
    "---  ------        --------------  -----   \n",
    " 0   age           11162 non-null  int8    \n",
    " 1   job           11162 non-null  category\n",
    " 2   marital       11162 non-null  category\n",
    " 3   education     11162 non-null  category\n",
    " 4   default       11162 non-null  bool    \n",
    " 5   balance       11162 non-null  int64   \n",
    " 6   housing       11162 non-null  bool    \n",
    " 7   loan          11162 non-null  bool    \n",
    " 8   contact       11162 non-null  category\n",
    " 9   month         11162 non-null  category\n",
    " 10  campaign      11162 non-null  int64   \n",
    " 11  pdays         11162 non-null  int64   \n",
    " 12  previous      11162 non-null  int64   \n",
    " 13  poutcome      11162 non-null  category\n",
    " 14  outcome       11162 non-null  bool    \n",
    " 15  day_of_week   11162 non-null  category\n",
    " 16  log_duration  11162 non-null  float64 \n",
    "dtypes: bool(4), category(7), float64(1), int64(4), int8(1)\n",
    "memory usage: 568.7 KB\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/trans_bank_marketing_codes-dtype.pk', 'rb') as file:\n",
    "    \n",
    "    dtypes_dict = pk.load(file)\n",
    "\n",
    "reg_df = pd.read_csv('data/trans_bank_marketing_codes.csv', dtype=dtypes_dict)\n",
    "reg_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesamiento\n",
    "\n",
    "Los datos son cargados y preprocesados según las herramientas vistas en el curso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separar variables explicativas de objetivo\n",
    "X = reg_df.loc[:, reg_df.columns[reg_df.columns != 'outcome']]\n",
    "y = reg_df['outcome']\n",
    "\n",
    "# separar conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# categorizar las columnas para ColumnTransformer\n",
    "\n",
    "int_cols = X_train.select_dtypes('int').columns.tolist()\n",
    "float_cols = X_train.select_dtypes('float').columns.tolist()\n",
    "bool_cols = X_train.select_dtypes('bool').columns.tolist()\n",
    "\n",
    "one_hot_cols = X_train.select_dtypes('category').columns.tolist() + \\\n",
    "    X_train.select_dtypes('int8').columns.tolist()\n",
    "\n",
    "# inicializar ColumnTransformer\n",
    "col_trans = ColumnTransformer([\n",
    "    ('continuous_std', StandardScaler(), float_cols),\n",
    "    ('minmax', MinMaxScaler(), int_cols),\n",
    "    ('passthrough_bool', 'passthrough', bool_cols),\n",
    "    ('one_hot', OneHotEncoder(drop='first'), one_hot_cols)\n",
    "])\n",
    "\n",
    "# asegurar todas las columnas del conjunto de datos son utilizadas\n",
    "assert X.columns.isin(int_cols + float_cols + bool_cols + one_hot_cols).all(), \\\n",
    "    'No todas las columnas son consideradas en ColumnTransformer'\n",
    "\n",
    "# obtener los arreglos que se utilizaran en el ejercicio\n",
    "X_mcmc = col_trans.fit_transform(X_train)\n",
    "X_mcmc = sparse.hstack((np.ones((X_mcmc.shape[0], 1)), X_mcmc))\n",
    "y_mcmc = y_train.astype(int).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión logística Bayesiana\n",
    "\n",
    "Dado un conjunto de observaciones para un problema de clasificación binario $\\mathcal{D}= \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^{N} \\in \\mathbb{R}^{d} \\times \\{0,1\\}$ el modelo de regresión logística se determina por:\n",
    "\n",
    "$$\n",
    "p(y_i = 1 | \\mathbf{x}) = \\sigma(\\mathbf{w}^T\\mathbf{x})\n",
    "$$\n",
    "\n",
    "donde:\n",
    "$$\n",
    "\\sigma(\\mathbf{w}^T\\mathbf{x}) = \\frac{1}{1 + \\exp{(- \\mathbf{w}^T\\mathbf{x}})}\n",
    "$$\n",
    "\n",
    "Se asume la convención $\\mathbf{x}_i = (x_i, 1) \\forall i$, $x_i$ vector de características, esto permite codificar $\\mathbf{w} \\in \\mathbb{R}^{d}$. La verosimilitud asociada a este modelo viene dada por:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{y} | \\mathbf{w})=\\prod_{n=1}^{N}  \\sigma(\\mathbf{w}^T\\mathbf{x}_n)^{y_n}\\left\\{1-\\sigma(\\mathbf{w}^T\\mathbf{x}_n)\\right\\}^{1-y_n}\n",
    "$$\n",
    "\n",
    "Si se escoge una probabilidad *prior* normal isotrópica $p(\\mathbf{w})= \\mathcal{N}\\left(\\mathbf{w} | \\mathrm{\\mu}_{w}, \\sigma_w^2 I \\right)$, el calculo de la distribución posterior $p(\\mathbf{w} | \\mathbf{y})$ se vuelve intratable. Esto pues, se hace necesario normalizar el producto de las probabilidades $p(\\mathbf{y} | \\mathbf{w})p(\\mathbf{w})$, para lo cual no se tiene una expresión analítica. Por tal motivo, la distribución posterior predictiva\n",
    "\n",
    "$$\n",
    "p(\\mathbf{y}_{*} | \\mathbf{w},\\mathbf{x}_{*}) = \\int \\sigma(\\mathbf{w}^T\\mathbf{x}_*) p(\\mathbf{w} | \\mathbf{y}) d\\mathbf{w}\n",
    "$$\n",
    "\n",
    "no puede ser calculada de manera explicita. Se busca por tanto, aproximar la probabilidad posterior $p(\\mathbf{w} | \\mathbf{y})$ y utilizar dicha aproximación para hacer predicciones por medio de $p(\\mathbf{y} | \\mathbf{w})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 1\n",
    "\n",
    "Para comenzar, se definen los objetos necesarios para capturar el modelo de regresión logística bayesiana.\n",
    "\n",
    "1. Defina con `numpy` la función sigmoide y la log verosimilitud de la regresión logística. Compruebe que para el vector `w_inicial` obtiene aproximadamente `-3271`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegresionLogisticaMixin():\n",
    "    '''Clase Mixin para el calculo de la log verosimilitud de un modelo \n",
    "    de regresion logistica'''\n",
    "    \n",
    "    def sigmoide(self, x):\n",
    "        # Implementación aca\n",
    "        \n",
    "    # metodo protegido (por compatibilidad de version posterior)\n",
    "    def _log_verosimilitud(self, w, X, y):\n",
    "        # Implementacion aca\n",
    "\n",
    "w_inicial = np.load('modelos/w_inicial.npy')\n",
    "RegresionLogisticaMixin()._log_verosimilitud(w_inicial, X_mcmc, y_mcmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCMC\n",
    "\n",
    "Para lograr la aproximación de $p(\\mathbf{y} | \\mathbf{w})$ se utiliza un esquema de *Markov Chain Monte Carlo* (MCMC). Este se basa en la construcción de una cadena de Markov con distribución estacionaria \n",
    "$p(\\mathbf{w} | \\mathbf{y})$. Para construir esta cadena, se generan muestras de $\\mathbf{w}$ en el espacio de estados $\\mathbb{R}^d$ por medio de una distribución generadora de propuestas $q(\\mathbf{w})$. Luego se define una regla de transición, por medio del cual se evalúa si las muestras propuestas son aceptadas como representantes de $p(\\mathbf{w} | \\mathbf{y})$. \n",
    "\n",
    "El resultado del esquema MCMC es un conjunto de muestras provenientes de la distribución posterior deseada. Es conjunto de muestras se denota como **traza**. Para comprender la dinámica de selección de muestras consideremos el siguiente caso:\n",
    "\n",
    "Supongamos que se acepta la muestra $\\mathbf{w}_1$, luego se genera una nueva muestra (propuesta) $\\mathbf{w}_2$ por medio de $q(\\cdot| \\mathbf{w}_1)$. Para evaluar si esta nueva muestra es aceptada como miembro de la cadena,  se define el *coeficiente de aceptación* $\\alpha ( \\mathbf{w}_1 , \\mathbf{w}_2 ) = \\min \\left[ 1 , \\frac { p ( \\mathbf{w}_2 | \\mathbf{y})  q ( \\mathbf{w}_1 | \\mathbf{w}_2 ) } { p ( \\mathbf{w}_1 | \\mathbf{y}) q (\\mathbf{w}_2 | \\mathbf{w}_1 ) } \\right]$. No se conoce el valor de  $p ( \\mathbf{w} | \\mathbf{y})$ pero se sabe que\n",
    "\n",
    "$$\n",
    "p(\\mathbf{w} | \\mathbf{y}) \\propto p(\\mathbf{y} | \\mathbf{w})p(\\mathbf{w})\n",
    "$$\n",
    "\n",
    "Luego \n",
    "\n",
    "$$\n",
    "\\frac { p ( \\mathbf{w}_2 | \\mathbf{y})  q ( \\mathbf{w}_1 | \\mathbf{w}_2 ) } { p ( \\mathbf{w}_1 | \\mathbf{y}) q (\\mathbf{w}_2 | \\mathbf{w}_1 ) } \n",
    "=\n",
    "\\frac { p(\\mathbf{y} | \\mathbf{w}_2)q ( \\mathbf{w}_1 | \\mathbf{w}_2 ) p(\\mathbf{w}_2)}{ p(\\mathbf{y} | \\mathbf{w}_1) q (\\mathbf{w}_2 | \\mathbf{w}_1 )p(\\mathbf{w}_1) }\n",
    "$$\n",
    "\n",
    "Lo cual nos permite simular muestras de la posterior por medio de evaluaciones de la verosimilitud y prior del modelo. La variante de MCMC propuesta en este ejercicio de conoce como *Metropolis Hastings*. El algoritmo se describe a continuación:\n",
    "\n",
    "0. Como entrada del algoritmo se requiere $\\mathbf{w}_0$, la verosimilitud del modelo, la probabilidad prior para $\\mathbf{w}$ y una distribución generadora de propuestas $q(\\cdot)$. Como salida del algoritmo se tendrán `N` vectores `w_1`, ..., `w_N`.\n",
    "\n",
    "1. Para `i=1` hasta `N`:\n",
    "    1. Obtener una muestra `w_prop` de $q(\\cdot |\\mathbf{w}_{i-1})$.\n",
    "    2. Obtener una muestra de una variable aleatoria uniforme $U$.\n",
    "    3. Si $U < \\frac { p(\\mathbf{y} | \\mathbf{w}_{prop})q ( \\mathbf{w}_{i-1} | \\mathbf{w}_{prop} ) p(\\mathbf{w}_{prop})}{ p(\\mathbf{y} | \\mathbf{w}_{i-1}) q (\\mathbf{w}_{prop} | \\mathbf{w}_1 )p(\\mathbf{w}_{i-1}) }$ entonces $\\mathbf{w}_i =$ `w_prop`. En caso contrario $\\mathbf{w}_i = \\mathbf{w}_{i-1}$.\n",
    "\n",
    "Dado que la convergencia a $p(\\mathbf{w} | \\mathbf{y})$ se tiene en el infinito, las primeras muestras obtenidas por la cadena no son recomendables como representantes de la distribución posterior, eliminar cierta cantidad de muestras al inicio de la cadena se denomina *quemar la cadena*. Por otra parte, dado que las muestras obtenidas provienen de una cadena de Markov, estas son altamente dependientes entre si, por lo que se recomienda seleccionar muestras de la traza cada cierta cantidad de *saltos* o *leaps* para evitar dependencia entre las muestras obtenidas. Por último, si se posee un conjunto de muestras $\\mathbf{w}_1, ..., \\mathbf{w}_M$ provenientes de $p(\\mathbf{w} | \\mathbf{y})$, es posible aproximar la distribución posterior predictiva por medio de:\n",
    "\n",
    "$$\n",
    "p(\\mathbf{y}_{*} | \\mathbf{w},\\mathbf{x}_{*}) = \\int \\sigma(\\mathbf{w}^T\\mathbf{x}_*) p(\\mathbf{w} | \\mathbf{y}) d\\mathbf{w} \\approx \\frac{1}{M} \\sum_{i = 1}^{M} \\sigma(\\mathbf{w}_i^T\\mathbf{x}_{*})\n",
    "$$\n",
    "\n",
    "\n",
    "A continuación se implementa dicho algoritmo para una distribución de propuestas normal isotrópica. Estudie con antención el código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegresionLogisticaBayesianaMHV0(\n",
    "        BaseEstimator, ClassifierMixin, RegresionLogisticaMixin):\n",
    "\n",
    "    def __init__(\n",
    "            self, w_inicial, media_priori, std_priori, std_proposal, n_muestras):\n",
    "\n",
    "        # parametros metropolis hastings\n",
    "        self.w_inicial = w_inicial\n",
    "        self.media_priori = media_priori\n",
    "        self.std_priori = std_priori\n",
    "        self.std_proposal = std_proposal\n",
    "        self.n_muestras = n_muestras\n",
    "\n",
    "        # atributos inferidos\n",
    "        self.dim_parametros = self.w_inicial.shape[0]\n",
    "        self.traza = np.zeros((self.n_muestras + 1, self.dim_parametros, ))\n",
    "        self.traza[0] = self.w_inicial\n",
    "\n",
    "    def get_metropolis_hastings_candidatos(self):\n",
    "        '''    \n",
    "        Obtiene las muestras de una normal multivariada isotropica para \n",
    "        utilizarlos como candidatos de la cadena de Markov.\n",
    "        '''\n",
    "        distribucion_candidatos = stats.multivariate_normal(\n",
    "            mean=np.zeros(self.dim_parametros), cov=(\n",
    "                self.std_proposal ** 2) * np.eye(self.dim_parametros))\n",
    "\n",
    "        return distribucion_candidatos.rvs(size=self.n_muestras)\n",
    "\n",
    "    def get_metropolis_hastings_uniformes(self):\n",
    "        '''    \n",
    "        Obtiene las muestras de una normal multivariada isotropica para \n",
    "        utilizarlos como candidatos de la cadena de Markov.\n",
    "        '''\n",
    "\n",
    "        return np.random.uniform(size=(self.n_muestras,))\n",
    "\n",
    "    def get_priori(self):\n",
    "        '''\n",
    "        Prior Gaussiana con media mu_w y covarianza esferica sigma_w**2 I\n",
    "        '''\n",
    "        return stats.multivariate_normal(mean=np.zeros(self.dim_parametros), cov=(\n",
    "            self.std_priori**2)*np.eye(self.dim_parametros))\n",
    "\n",
    "    def metropolis_hastings(self, X, y, semilla):\n",
    "        '''\n",
    "        Muestrea el espacio de los parametros mediante Metropolis-Hastings\n",
    "        '''\n",
    "\n",
    "        # asegura replicabilidad\n",
    "        np.random.seed(semilla)\n",
    "\n",
    "        # obtiene distribucion a priori y candidatos\n",
    "        distribucion_priori = self.get_priori()\n",
    "        W_candidatos = self.get_metropolis_hastings_candidatos()\n",
    "        U_aceptacion = self.get_metropolis_hastings_uniformes()\n",
    "\n",
    "        # contador de candidatos aceptados\n",
    "        aceptados = 0\n",
    "\n",
    "        for i, w_candidato in enumerate(W_candidatos):\n",
    "\n",
    "            # localiza distribucion candidatos en w_actual\n",
    "            w_actual = self.traza[i]\n",
    "            w_candidato += w_actual\n",
    "\n",
    "            # calcula prior\n",
    "            delta_prior = distribucion_priori.logpdf(w_candidato) - \\\n",
    "                distribucion_priori.logpdf(w_actual)\n",
    "\n",
    "            # calcula verosimilitud\n",
    "            delta_verosimilitud = self._log_verosimilitud(w_candidato, X, y) - \\\n",
    "                self._log_verosimilitud(w_actual, X, y)\n",
    "\n",
    "            # probabilidad de aceptacion\n",
    "            p_aceptacion = math.exp(delta_verosimilitud + delta_prior)\n",
    "\n",
    "            if U_aceptacion[i] < p_aceptacion:\n",
    "\n",
    "                # actualiza valor actual y contador de aceptados\n",
    "                w_actual = w_candidato\n",
    "                aceptados += 1\n",
    "\n",
    "            self.traza[i+1] = w_actual\n",
    "\n",
    "        # almacena la proporcion de candidatos aceptados\n",
    "        self.proporcion_aceptacion = aceptados / self.n_muestras\n",
    "\n",
    "    def fit(self, X, y, n_muestras_quemadas=0, leap=10, semilla=6202):\n",
    "\n",
    "        # obtener traza mediante Metropolis Hastings\n",
    "        self.metropolis_hastings(X, y, semilla)\n",
    "\n",
    "        # obtener muestras posterior\n",
    "        self.w_post = self.traza[n_muestras_quemadas::leap, ]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        # Aproximacion de la posterior predictiva\n",
    "        return np.mean(self.sigmoide(X @ self.w_post.T), axis=1)\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        # maneja aproximacion de 0.5 a 1 (por comportamiento \"round half\n",
    "        # to even\")\n",
    "        return np.round(1 + self.predict_proba(X)) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comprueban los resultados de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parametros MCMC\n",
    "_, std_inicial = stats.norm.fit(w_inicial, floc=0)\n",
    "media_prior = np.zeros(w_inicial.shape)\n",
    "std_poposal = 1e-2\n",
    "n_samples = int(1e3) \n",
    "\n",
    "# Entrenamiento\n",
    "rlb_v0 = RegresionLogisticaBayesianaMHV0(w_inicial,media_prior,std_inicial,std_poposal,n_samples)\n",
    "rlb_v0.fit(X_mcmc, y_mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados\n",
    "ac_rlb = accuracy_score(rlb_v0.predict(X_mcmc), y_mcmc)\n",
    "print('Accuracy en conjunto de entrnamiento: ', ac_rlb)\n",
    "print('Proporcion de muestras aceptadas MCMC:', rlb_v0.proporcion_aceptacion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reporte el tiempo de ejecución de cada línea del método `metropolis_hastings` en un archivo de texto llamado `RegresionLogisticaBayesianaMHV0.txt` en la carpeta `reportes`. Compruebe que  más de un 90% del tiempo se utiliza en la función `log_verosimilitud`. En lo que queda del ejercicio nos dedicaremos a optimizar este método. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 3\n",
    "**Optimice el algoritmo**: \n",
    "\n",
    "1. Haga anulación (*overriding*) del método `metropolis_hastings` para evitar que para un mismo input se compute más de una vez la log verosimilitud y la log probabilidad *a priori*. \n",
    "2. Discuta en la celda subsiguiente por qué el uso de `@lru_cache` no es ideal.\n",
    "3. Reporte el tiempo de ejecución de cada línea del método `metropolis_hastings` en un archivo de texto llamado `RegresionLogisticaBayesianaMHV1.txt` en la carpeta `reportes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construya RegresionLogisticaBayesianaMHV1 aqui\n",
    "class RegresionLogisticaBayesianaMHV1(RegresionLogisticaBayesianaMHV0):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escriba su discusión aquí.** (Extensión máxima 400 caracteres)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reporte el tiempo de ejecucion aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 4\n",
    "**Procesos distribuidos**. \n",
    "\n",
    "1. Implemente la clase `ProcesoRegresionLogisticaBayesianaMHV1`, que herede de `Process` y `RegresionLogisticaBayesianaMHV1`, cuyo objetivo es guardar en el disco la traza obtenida en el proceso de entrenamiento.\n",
    "2. Obtenga tantas trazas de como nucleos tenga el procesador de su computador. Dichas trazas deben ser guardadas en la carpeta `trazas`, con el nombre del archivo según el formato `s_DDDD.npy` donde `DDDD` es un entero de 4 dígitos que representa la semilla utilizada para la obtención de dicha traza. *Hint*: puede obtener el número de núcleos de su procesador mediante la función `cpu_count()` de la librería `multiprocessing`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construya ProcesoRegresionLogisticaBayesianaMHV1 aqui\n",
    "class ProcesoRegresionLogisticaBayesianaMHV1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log verosimilitud en Cython\n",
    "Para finalizar implementaremos una versión en Cython para la log verosimilitud. En la siguiente celda adaptaremos los tipos de datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cython = X_mcmc.toarray().astype('float32')\n",
    "y_cython = y_mcmc.astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregunta 5\n",
    "**Versión cython de la Log veorsimilitud**\n",
    "\n",
    "1. Implemente la clase de cython `LogVerosimilitud`. Esta debe:\n",
    "    - Inicializarse con los argumentos `X` e `y` de tamaño conocido, es decir puede asumir que `X.shape = (8371, 56)` y que `y.shape = (8371,)`. *Hint*: Puede ser útil usar variables globales por medio del comando `DEF`.\n",
    "    - Poseer el método `get()` que opera sobre un arreglo de NumPy `w` y retorna su log verosimilitud. *Hint*: puede ser de utilidad el decorador `@cython.cdivision`.\n",
    "    - Transformar los arreglos de numpy (`X`, `y` y `w`) en arreglos de C.\n",
    "    - Minimizar la interacción con python, para acelerar el cómputo lo más posible. Para verificar esto utilice el `magic` de celda `%%cython -a`.\n",
    "\n",
    "*Hint*: utilice las funciones `exp` y `log` de `libc.math` de `cython`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython -a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compruebe que su implementación retorna la verosimilitud ya conocida para `w_inicial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compruebe que dados los mismos inputs `X_cython` y `y_cython`, la versión de Cython es más eficaz, pero que sin embargo, la más rápida es la versión de `numpy` en los inputs de `X_mcmc` e `y_mcmc`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus (sin puntaje)\n",
    "\n",
    "El valor de `w_inicial` utilizado en este ejercicio fue obtenido por medio de máxima verosimilitud. A continuación compararemos los resultados de scikit-learn, utilizando el parámetro de máxima verosimilitud con el enfoque bayesiano implementado a lo largo de esta evaluación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(X, w):\n",
    "    '''\n",
    "    Clasificador Logistico\n",
    "    '''\n",
    "    mixin = RegresionLogisticaMixin()\n",
    "    probs = mixin.sigmoide(X @ w)\n",
    "    \n",
    "    return np.round(1 + probs) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparar los datos del conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mcmc_test = col_trans.fit_transform(X_test)\n",
    "X_mcmc_test = sparse.hstack((np.ones((X_mcmc_test.shape[0], 1)), X_mcmc_test))\n",
    "y_mcmc_test = y_test.astype(int).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se inicaliza el modelo bayesiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, std_inicial = stats.norm.fit(w_inicial, floc=0)\n",
    "media_prior = np.zeros(w_inicial.shape)\n",
    "std_poposal = 1e-2\n",
    "n_samples = int(1e3)\n",
    "\n",
    "rlb_v1 = RegresionLogisticaBayesianaMHV1(w_inicial, media_prior, std_inicial,\n",
    "                                         std_poposal, n_samples)\n",
    "rlb_v1.fit(X_mcmc, y_mcmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparación en métricas de rendimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sklearn = log_reg(X_mcmc_test, w_inicial)\n",
    "y_pred_rlb = rlb_v1.predict(X_mcmc_test)\n",
    "\n",
    "ac_skl = accuracy_score(y_pred_sklearn, y_test)\n",
    "f1_skl = f1_score(y_pred_sklearn, y_test)\n",
    "ac_rlb = accuracy_score(y_pred_rlb, y_test)\n",
    "f1_rlb = f1_score(y_pred_rlb, y_test)\n",
    "print('Accuracy sk-learn: ', ac_skl)\n",
    "print('F1 score sk-learn: ', f1_skl)\n",
    "print('Accuracy RLB: ', ac_rlb)\n",
    "print('F1 score RLB: ', f1_rlb)\n",
    "print(f'Ac RLB >= MLE: {ac_rlb >= ac_skl}    F1 RLB >= MLE: {f1_rlb >= f1_skl}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizar la posterior cargamos las trazas obtenidas durante el ejercicio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_files = sorted(glob.glob('trazas/*.npy'))\n",
    "traza_concat = None\n",
    "\n",
    "for filename in np_files:\n",
    "    \n",
    "    traza = np.load(filename)\n",
    "    \n",
    "    if traza_concat is None:\n",
    "        \n",
    "        traza_concat = traza\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        traza_concat = np.concatenate((traza_concat, traza), axis=0)\n",
    "        \n",
    "traza_concat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos la traza como la distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_fig = 'fig'\n",
    "archivo_figura = f'{dir_fig}/prop-{std_poposal:.0e}_nsamples-{n_samples:.0e}.png'\n",
    "sobrescribe = False\n",
    "\n",
    "xx = np.arange(traza_concat.shape[0])\n",
    "w_esperado = traza_concat.mean(0)\n",
    "\n",
    "nrows, ncols = traza_concat.shape[1], 2\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(5 * ncols, 3 * nrows), \n",
    "                         gridspec_kw={'hspace':.3})\n",
    "for i in range(nrows):\n",
    "    \n",
    "    # histograma posterior\n",
    "    ax_ = axes[i, 0]\n",
    "    ax_.set_title('Posterior w_' + str(i))\n",
    "    \n",
    "    # evita FutureWarnings en distplot\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "        sns.distplot(traza_concat[:, i], ax=ax_)\n",
    "        \n",
    "    ax_.set_ylabel('frecuencia')\n",
    "    ax_.axvline(x=w_inicial[i], label='MLE', ls= '-.', c = 'r')\n",
    "    ax_.axvline(x=w_esperado[i], label = 'Esperado',ls= '--', c='black')\n",
    "    ax_.legend()\n",
    "    \n",
    "    # traza\n",
    "    ax_ = axes[i, 1]\n",
    "    ax_.scatter(x=xx, y = traza_concat[:, i], alpha=.6, s=.1)\n",
    "    ax_.set_ylabel('w_' + str(i))\n",
    "    ax_.set_title('Traza w_' + str(i))\n",
    "    \n",
    "axes[i, 0].set_xlabel('w_' + str(i));\n",
    "axes[i, 1].set_xlabel('Iteraciones'); \n",
    "if (not os.path.isfile(archivo_figura)) or sobrescribe:\n",
    "    fig.savefig(archivo_figura, bbxox_inches='tight')\n",
    "else:\n",
    "    print(f'Archivo existente,  y `sobrescribe` = {sobrescribe}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "es",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
